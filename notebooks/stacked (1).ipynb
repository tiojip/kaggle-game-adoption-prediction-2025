{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec915028-e3fb-4bb1-9d20-8461088153f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\flero\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\flero\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\flero\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c77d986-04b1-49dd-a269-48942ee74354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd79773-0d45-4f33-bda1-691175e5d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©pertoire courant : C:\\Users\\flero\\Downloads\n"
     ]
    }
   ],
   "source": [
    "# Afficher le r√©pertoire courant\n",
    "print(\"R√©pertoire courant :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae68618-e0b6-4ea7-aa66-7bc59a0dbf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau r√©pertoire : D:\\HEC\\Msc BI\\Data Mining\\Devoir Hiver\n"
     ]
    }
   ],
   "source": [
    "# Changer de r√©pertoire (remplacez le chemin par celui de votre dossier)\n",
    "os.chdir(r'D:\\HEC\\Msc BI\\Data Mining\\Devoir Hiver')\n",
    "print(\"Nouveau r√©pertoire :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79135816-ae5c-42a2-9f34-e516e4e60e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de mobiletrain : (5000, 17)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importation des donn√©es\n",
    "# Ici, nous utilisons pd.read_csv() pour lire les fichiers texte.\n",
    "# L'argument sep=r'\\s+' pr√©cise que les colonnes sont s√©par√©es par des espaces.\n",
    "mobiletrain = pd.read_csv(\"train.csv\", sep=',')\n",
    "mobiletest  = pd.read_csv(\"test.csv\", sep=',')\n",
    "\n",
    "# Affichage des dimensions du DataFrame mobiletrain\n",
    "# L'attribut .shape renvoie un tuple (nombre de lignes, nombre de colonnes)\n",
    "print(\"Dimensions de mobiletrain :\", mobiletrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833c28a9-36ab-4874-9185-0aa52a57620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bf36998-8e22-4a64-8b19-46895d3c62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsOneClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aefb90c9-67ea-4978-9590-54320759a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flero\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:53:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\flero\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:53:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\flero\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:53:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\flero\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:53:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier 'submission_stacked.csv' g√©n√©r√© avec succ√®s üéâ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Nettoyage des colonnes ---\n",
    "mobiletrain.columns = mobiletrain.columns.str.strip()\n",
    "mobiletest.columns = mobiletest.columns.str.strip()\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "def add_features(df):\n",
    "    df['avg_score_per_session'] = df['totscore'] / (df['numsessions'] + 1)\n",
    "    df['avg_purchase_per_session'] = df['totpurchases'] / (df['numsessions'] + 1)\n",
    "    df['playtime_per_day'] = df['totplaytime'] / (df['numdays'] + 1)\n",
    "    df['score_per_day'] = df['totscore'] / (df['numdays'] + 1)\n",
    "    df['purchase_efficiency'] = df['totpurchases'] / (df['totscore'] + 1)\n",
    "    df['lives_per_day'] = df['numlives'] / (df['numdays'] + 1)\n",
    "    df['elements_per_session'] = df['numelements'] / (df['numsessions'] + 1)\n",
    "    df['difficulty_ratio'] = df['difflevel'] / (df['skill1'] + df['skill2'] + 1)\n",
    "    df['acquisition_trend_interaction'] = df['acquis'] * df['trendpurchase']\n",
    "    df['platform_trend_combo'] = df['opsys'] * df['trendsession']\n",
    "    return df\n",
    "\n",
    "mobiletrain = add_features(mobiletrain)\n",
    "mobiletest = add_features(mobiletest)\n",
    "\n",
    "# --- Pr√©paration des donn√©es ---\n",
    "X = pd.get_dummies(mobiletrain.drop(columns=['y']))\n",
    "y = mobiletrain['y']\n",
    "X_test = pd.get_dummies(mobiletest.drop(columns=['id']))\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# --- Split pour train/meta-model ---\n",
    "X_train, X_meta, y_train, y_meta = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "# --- 1. XGBoost Multiclass ---\n",
    "xgb_multi = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=4,\n",
    "    eval_metric='mlogloss',\n",
    "    n_estimators=734,\n",
    "    learning_rate=0.17687238367091132,\n",
    "    max_depth=5, \n",
    "    min_child_weight=9,\n",
    "    subsample=0.7167772586450419,\n",
    "    colsample_bytree=0.8636447281342982,\n",
    "    gamma=0.9995326576561295,\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_multi.fit(X_train, y_train)\n",
    "multi_proba = xgb_multi.predict_proba(X_meta)\n",
    "\n",
    "# --- 2. XGBoost OvO ---\n",
    "base_model_ovo = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=734,\n",
    "    learning_rate=0.17687238367091132,\n",
    "    max_depth=5, \n",
    "    min_child_weight=9,\n",
    "    subsample=0.7167772586450419,\n",
    "    colsample_bytree=0.8636447281342982,\n",
    "    gamma=0.9995326576561295,\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "ovo_model = OneVsOneClassifier(base_model_ovo)\n",
    "ovo_model.fit(X_train, y_train)\n",
    "ovo_proba = ovo_model.predict(X_meta).reshape(-1, 1)  # shape = (n_samples, 4)\n",
    "\n",
    "# --- 3. Concat√©nation des pr√©dictions ---\n",
    "meta_features = np.hstack([multi_proba, ovo_proba])  # 8 features = 4 proba + 4 proba\n",
    "\n",
    "# --- 4. Entra√Ænement du m√©ta-mod√®le ---\n",
    "meta_model = LogisticRegression(max_iter=200)\n",
    "meta_model.fit(meta_features, y_meta)\n",
    "\n",
    "# --- 5. G√©n√©rer les pr√©dictions finales sur X_test ---\n",
    "# Pr√©dictions base models sur X_test\n",
    "multi_test_proba = xgb_multi.predict_proba(X_test)\n",
    "ovo_test_proba = ovo_model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "# Concat√©nation\n",
    "meta_test_input = np.hstack([multi_test_proba, ovo_test_proba])\n",
    "\n",
    "# Pr√©dictions finales\n",
    "y_test_pred_encoded = meta_model.predict(meta_test_input)\n",
    "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
    "\n",
    "# --- 6. Cr√©ation du fichier de soumission ---\n",
    "submission_stacked = pd.DataFrame({\n",
    "    'id': mobiletest['id'],\n",
    "    'Prediction': y_test_pred\n",
    "})\n",
    "\n",
    "submission_stacked.to_csv(\"submission_stacked.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Fichier 'submission_stacked.csv' g√©n√©r√© avec succ√®s üéâ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40948018-ff6c-4e62-8a29-61e9bf663236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
